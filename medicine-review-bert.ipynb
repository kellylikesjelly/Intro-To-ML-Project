{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using BERT to classify medicine reviews\nIn this dataset (UCI Medicine Reviews), our task was to predict the condition the reviewer was suffering from based on their review. In this notebook, I finetune BERT with a sequence classification head to predict the condition using the reviews.","metadata":{}},{"cell_type":"code","source":"#import required libraries\n#a script from https://github.com/Bjarten/early-stopping-pytorch#:~:text=Early%20stopping%20is%20a%20form,a%20row%20the%20training%20stops.\nimport torch\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport regex as re\nfrom sklearn.model_selection import train_test_split\nfrom early_stopping_script import EarlyStopping\nfrom torch.utils.data import DataLoader\nimport itertools","metadata":{"id":"u8oBTrn6Z1JY","execution":{"iopub.status.busy":"2022-01-11T12:08:24.587023Z","iopub.execute_input":"2022-01-11T12:08:24.587962Z","iopub.status.idle":"2022-01-11T12:08:26.685182Z","shell.execute_reply.started":"2022-01-11T12:08:24.587835Z","shell.execute_reply":"2022-01-11T12:08:26.684486Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#import data into dataframes\ntrain = pd.read_csv('/kaggle/input/drug-reviews/drugLibTrain_raw.tsv', sep='\\t')\ntest = pd.read_csv('/kaggle/input/drug-reviews/drugLibTest_raw.tsv', sep='\\t')","metadata":{"id":"mvA8JFz1aL3F","execution":{"iopub.status.busy":"2022-01-11T12:08:26.686967Z","iopub.execute_input":"2022-01-11T12:08:26.687202Z","iopub.status.idle":"2022-01-11T12:08:26.791968Z","shell.execute_reply.started":"2022-01-11T12:08:26.687170Z","shell.execute_reply":"2022-01-11T12:08:26.791279Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:08:26.793814Z","iopub.execute_input":"2022-01-11T12:08:26.794057Z","iopub.status.idle":"2022-01-11T12:08:26.819924Z","shell.execute_reply.started":"2022-01-11T12:08:26.794022Z","shell.execute_reply":"2022-01-11T12:08:26.819258Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"There are some missing values, so we will drop those rows.","metadata":{}},{"cell_type":"code","source":"train.dropna(inplace=True)\ntest.dropna(inplace=True)","metadata":{"id":"XQYBZa1En-mD","execution":{"iopub.status.busy":"2022-01-11T12:08:26.822102Z","iopub.execute_input":"2022-01-11T12:08:26.822710Z","iopub.status.idle":"2022-01-11T12:08:26.834116Z","shell.execute_reply.started":"2022-01-11T12:08:26.822673Z","shell.execute_reply":"2022-01-11T12:08:26.833482Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#we will be doing EDA on the entire dataset\ntrain = pd.concat([train, test])","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:08:26.835631Z","iopub.execute_input":"2022-01-11T12:08:26.835816Z","iopub.status.idle":"2022-01-11T12:08:26.844473Z","shell.execute_reply.started":"2022-01-11T12:08:26.835794Z","shell.execute_reply":"2022-01-11T12:08:26.843838Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation\nWe will only be using the benefits, side effects and overall comments reviews as our predictors.","metadata":{}},{"cell_type":"code","source":"#combine the reviews into one column\ntrain['combinedReview'] = train['benefitsReview'] + '.' + \\\n        train['sideEffectsReview'] + '.' + train['commentsReview']","metadata":{"id":"9wnwPhJ7a9V5","execution":{"iopub.status.busy":"2022-01-11T12:08:26.845973Z","iopub.execute_input":"2022-01-11T12:08:26.846382Z","iopub.status.idle":"2022-01-11T12:08:26.856556Z","shell.execute_reply.started":"2022-01-11T12:08:26.846348Z","shell.execute_reply":"2022-01-11T12:08:26.855792Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#check number of classes\ntrain['condition'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:08:26.858006Z","iopub.execute_input":"2022-01-11T12:08:26.858577Z","iopub.status.idle":"2022-01-11T12:08:26.870235Z","shell.execute_reply.started":"2022-01-11T12:08:26.858539Z","shell.execute_reply":"2022-01-11T12:08:26.868899Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#check distribution of classes\nsns.boxplot(data = train['condition'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:08:26.871787Z","iopub.execute_input":"2022-01-11T12:08:26.872495Z","iopub.status.idle":"2022-01-11T12:08:27.155955Z","shell.execute_reply.started":"2022-01-11T12:08:26.872457Z","shell.execute_reply":"2022-01-11T12:08:27.155263Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"There are many conditions, most of which have very few observations (the median is less than 10). Hence there is insufficient data for them and we will only predict for the top 10 classes.","metadata":{}},{"cell_type":"code","source":"#only get rows for top 10 conditions by observation count\ntop_10_conditions = train['condition'].value_counts(ascending=False).index[:10]\ntop_10 = train[train['condition'].isin(top_10_conditions)]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:08:27.157314Z","iopub.execute_input":"2022-01-11T12:08:27.157579Z","iopub.status.idle":"2022-01-11T12:08:27.167682Z","shell.execute_reply.started":"2022-01-11T12:08:27.157547Z","shell.execute_reply":"2022-01-11T12:08:27.166885Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#check distribution of classes for top 10 conditions\nsns.boxplot(data = top_10['condition'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:08:27.169017Z","iopub.execute_input":"2022-01-11T12:08:27.169281Z","iopub.status.idle":"2022-01-11T12:08:27.318384Z","shell.execute_reply.started":"2022-01-11T12:08:27.169248Z","shell.execute_reply":"2022-01-11T12:08:27.317720Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"top_10['condition'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:08:27.319649Z","iopub.execute_input":"2022-01-11T12:08:27.319878Z","iopub.status.idle":"2022-01-11T12:08:27.327528Z","shell.execute_reply.started":"2022-01-11T12:08:27.319846Z","shell.execute_reply":"2022-01-11T12:08:27.326828Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#check lengths of reviews (number of tokens)\nlengths_combinedReview = top_10['combinedReview'].str.split().str.len()\nsns.boxplot(data = lengths_combinedReview.reset_index(drop=True))","metadata":{"id":"hT_4hZQKbCPI","outputId":"cf91a958-455b-4d9a-d765-387b2fdafeee","execution":{"iopub.status.busy":"2022-01-11T12:08:27.328762Z","iopub.execute_input":"2022-01-11T12:08:27.329167Z","iopub.status.idle":"2022-01-11T12:08:27.479854Z","shell.execute_reply.started":"2022-01-11T12:08:27.329128Z","shell.execute_reply":"2022-01-11T12:08:27.479139Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"There are outliers with more than 300 words. For BERT, to balance speed of training and accuracy, the limit of number of tokens will be adjusted to 250.","metadata":{}},{"cell_type":"code","source":"#extract only the columns needed\ntop_10_shorter = top_10[['condition', 'combinedReview']].copy()\ntop_10_shorter.head()","metadata":{"id":"sG_GzT2FdhQs","outputId":"8a409891-5ce1-4afd-ba3b-cf4cf9a0c1f2","execution":{"iopub.status.busy":"2022-01-11T12:08:27.481027Z","iopub.execute_input":"2022-01-11T12:08:27.481451Z","iopub.status.idle":"2022-01-11T12:08:27.497100Z","shell.execute_reply.started":"2022-01-11T12:08:27.481409Z","shell.execute_reply":"2022-01-11T12:08:27.496408Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#remove links from reviews\ndef clean_text(x):\n    y = re.sub(r'(?:http:\\/\\/)?www\\.[^\\s\\,]+', '', x, flags=re.IGNORECASE)\n    return y\n\ntop_10_shorter['combinedReview'] = top_10_shorter['combinedReview'].apply(lambda x: clean_text(x))","metadata":{"id":"X1jn6-mvd3mE","execution":{"iopub.status.busy":"2022-01-11T12:08:27.501058Z","iopub.execute_input":"2022-01-11T12:08:27.501589Z","iopub.status.idle":"2022-01-11T12:08:27.518598Z","shell.execute_reply.started":"2022-01-11T12:08:27.501547Z","shell.execute_reply":"2022-01-11T12:08:27.517946Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#generate class labels for input into BERT\ntop_10_shorter['condition_code'] = top_10_shorter.groupby('condition').ngroup()\nclasses = top_10_shorter[['condition', 'condition_code']].drop_duplicates().sort_values('condition_code')['condition']\nclasses","metadata":{"id":"hr-BCYcHqkPk","execution":{"iopub.status.busy":"2022-01-11T12:08:27.519790Z","iopub.execute_input":"2022-01-11T12:08:27.520016Z","iopub.status.idle":"2022-01-11T12:08:27.534740Z","shell.execute_reply.started":"2022-01-11T12:08:27.519985Z","shell.execute_reply":"2022-01-11T12:08:27.533795Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#stratified sampling - train test split\nX_train, X_test, y_train, y_test = train_test_split(top_10_shorter['combinedReview'], top_10_shorter['condition_code'], \n                                                    test_size=0.2, random_state=42, shuffle=True, stratify=top_10_shorter['condition_code'])\n#train val split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n                                                    test_size=0.15, random_state=42, shuffle=True, stratify=y_train)","metadata":{"id":"VGRxiFQ4Bm4p","execution":{"iopub.status.busy":"2022-01-11T12:08:27.536191Z","iopub.execute_input":"2022-01-11T12:08:27.536711Z","iopub.status.idle":"2022-01-11T12:08:27.551273Z","shell.execute_reply.started":"2022-01-11T12:08:27.536586Z","shell.execute_reply":"2022-01-11T12:08:27.550633Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(f'No. train observations: {len(X_train)}')\nprint(f'No. validation observations: {len(X_val)}')\nprint(f'No. test observations: {len(X_test)}')","metadata":{"id":"jnjACh06DxLL","outputId":"f6e66cab-2def-40ea-abce-0c522dce3fee","execution":{"iopub.status.busy":"2022-01-11T12:08:27.552585Z","iopub.execute_input":"2022-01-11T12:08:27.552846Z","iopub.status.idle":"2022-01-11T12:08:27.559205Z","shell.execute_reply.started":"2022-01-11T12:08:27.552812Z","shell.execute_reply":"2022-01-11T12:08:27.558411Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(15, 5))\nfig.suptitle('Distribution of Classes')\n\n# Overall\nsns.countplot(ax=axes[0, 0], data=top_10_shorter['condition_code'], \\\n              x=top_10_shorter['condition_code'].values)\naxes[0, 0].set_title('Overall')\n\n# Train\nsns.countplot(ax=axes[0, 1], data=y_train, x=y_train.values)\naxes[0, 1].set_title('Train')\n\n# Validation\nsns.countplot(ax=axes[1, 0], data=y_val, x=y_val.values)\naxes[1, 0].set_title('Validation')\n\n# Test\nsns.countplot(ax=axes[1, 1], data=y_test, x=y_test.values)\naxes[1, 1].set_title('Test')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:08:27.560527Z","iopub.execute_input":"2022-01-11T12:08:27.561411Z","iopub.status.idle":"2022-01-11T12:08:28.132621Z","shell.execute_reply.started":"2022-01-11T12:08:27.561311Z","shell.execute_reply":"2022-01-11T12:08:28.131963Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"The proportions of each class is the same in all the datasets.","metadata":{}},{"cell_type":"code","source":"#customised dataset to accept dataframe input\n#dataset classes are used to wrap the data rows for access by other classes like dataloader\nclass ReviewsDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe):\n        self.dataframe = dataframe\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        #returns (label, x) to collate function\n        row = self.dataframe.iloc[index]\n        return (\n            row['condition_code'],\n            row['combinedReview']\n        )","metadata":{"id":"RK-Pkcl2qPPL","execution":{"iopub.status.busy":"2022-01-11T12:08:28.133663Z","iopub.execute_input":"2022-01-11T12:08:28.134219Z","iopub.status.idle":"2022-01-11T12:08:28.140476Z","shell.execute_reply.started":"2022-01-11T12:08:28.134170Z","shell.execute_reply":"2022-01-11T12:08:28.139404Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#format train val test series back into df to load into dataset\ntrain_df = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\ntest_df = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)\nval_df = pd.concat([X_val, y_val], axis=1).reset_index(drop=True)","metadata":{"id":"w25ApMCPEtDh","execution":{"iopub.status.busy":"2022-01-11T12:08:28.142079Z","iopub.execute_input":"2022-01-11T12:08:28.142505Z","iopub.status.idle":"2022-01-11T12:08:28.154311Z","shell.execute_reply.started":"2022-01-11T12:08:28.142432Z","shell.execute_reply":"2022-01-11T12:08:28.153674Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#create datasets\ntrainset = ReviewsDataset(train_df)\ntestset = ReviewsDataset(test_df)\nvalset = ReviewsDataset(val_df)","metadata":{"id":"TXUGiLtTFDU4","execution":{"iopub.status.busy":"2022-01-11T12:08:28.155295Z","iopub.execute_input":"2022-01-11T12:08:28.155536Z","iopub.status.idle":"2022-01-11T12:08:28.166897Z","shell.execute_reply.started":"2022-01-11T12:08:28.155501Z","shell.execute_reply":"2022-01-11T12:08:28.166081Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#load BERT tokenizer from torch hub\ntokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')","metadata":{"id":"FOk-O13Er6rB","outputId":"3a900919-5dc8-4c3e-947f-7685a62d08d0","execution":{"iopub.status.busy":"2022-01-11T12:08:28.168301Z","iopub.execute_input":"2022-01-11T12:08:28.168656Z","iopub.status.idle":"2022-01-11T12:08:42.122916Z","shell.execute_reply.started":"2022-01-11T12:08:28.168619Z","shell.execute_reply":"2022-01-11T12:08:42.122238Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#detect if using CUDA or CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"GMnTKcnG1qRJ","execution":{"iopub.status.busy":"2022-01-11T12:08:42.124186Z","iopub.execute_input":"2022-01-11T12:08:42.124428Z","iopub.status.idle":"2022-01-11T12:08:42.169361Z","shell.execute_reply.started":"2022-01-11T12:08:42.124396Z","shell.execute_reply":"2022-01-11T12:08:42.168510Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#define collation function - how to return a batch of data\n#return 3 tensors required by BERT: labels, token ids, attention masks\n#labels - class the observation belongs to\n#token ids - the numerical id of the token e.g. [PAD] has an ID of 0\n#attention mask - indicates the position of paddings [PAD] is 0, anything else is 1\n#label size (batch size,)\n#token id size (batch size, max_length)\n#attention mask size (batch size, max_length)\n\ndef collate_batch(batch):\n    labels, token_ids, attention_masks = [], [], []\n    for (label, review) in batch:\n        #produces dictionary of token ids and attention mask\n        #truncation=True to truncate reviews longer than 250 tokens\n        encoded_dict = tokenizer.encode_plus(\n                        review,\n                        add_special_tokens = True,\n                        max_length = 250,\n                        padding = 'max_length',\n                        return_attention_mask = True,\n                        return_tensors = 'pt',\n                        truncation = True)\n        labels.append(label)\n        token_ids.append(encoded_dict['input_ids'])\n        attention_masks.append(encoded_dict['attention_mask'])\n    label_tensor = torch.tensor(labels, dtype=torch.int64)\n    token_tensor = torch.cat(token_ids, dim=0)\n    attention_tensor = torch.cat(attention_masks, dim=0)\n    #.to converts the tensor into appropriate form (CPU or GPU)\n    return label_tensor.to(device), token_tensor.to(device), attention_tensor.to(device)","metadata":{"id":"uFwGwCCicYVM","execution":{"iopub.status.busy":"2022-01-11T12:08:42.171157Z","iopub.execute_input":"2022-01-11T12:08:42.171769Z","iopub.status.idle":"2022-01-11T12:08:42.180988Z","shell.execute_reply.started":"2022-01-11T12:08:42.171727Z","shell.execute_reply":"2022-01-11T12:08:42.180349Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#create dataloaders which use the custom collation function\n#shuffle to reduce dependency of training on order of observations\ntrainloader = DataLoader(trainset, batch_size=32, collate_fn= collate_batch, shuffle=True)\nvalloader = DataLoader(valset, batch_size=25, collate_fn= collate_batch, shuffle=True)\ntestloader = DataLoader(testset, batch_size=32, collate_fn= collate_batch, shuffle=True)","metadata":{"id":"ok48DsDIDz4c","execution":{"iopub.status.busy":"2022-01-11T12:08:42.183722Z","iopub.execute_input":"2022-01-11T12:08:42.184278Z","iopub.status.idle":"2022-01-11T12:08:42.192079Z","shell.execute_reply.started":"2022-01-11T12:08:42.184239Z","shell.execute_reply":"2022-01-11T12:08:42.191302Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#get one sample batch\niterator = iter(trainloader)\nlabels, tokens, attention = iterator.next()","metadata":{"id":"ORJoZ5PurtaM","execution":{"iopub.status.busy":"2022-01-11T12:08:42.194907Z","iopub.execute_input":"2022-01-11T12:08:42.195108Z","iopub.status.idle":"2022-01-11T12:08:46.804198Z","shell.execute_reply.started":"2022-01-11T12:08:42.195084Z","shell.execute_reply":"2022-01-11T12:08:46.803289Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(labels[0])\nprint(tokens[0])\nprint(attention[0])","metadata":{"id":"XyCjFhIwvL7p","outputId":"3d4e5f07-7a0f-4932-b369-f4309705bfe4","execution":{"iopub.status.busy":"2022-01-11T12:08:46.809452Z","iopub.execute_input":"2022-01-11T12:08:46.809741Z","iopub.status.idle":"2022-01-11T12:08:46.842186Z","shell.execute_reply.started":"2022-01-11T12:08:46.809704Z","shell.execute_reply":"2022-01-11T12:08:46.841403Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#load pretrained BERT for seq classification from pytorch hub\nmodel = torch.hub.load('huggingface/pytorch-transformers', 'modelForSequenceClassification', 'bert-base-uncased', num_labels=10)","metadata":{"id":"ddFuyjiUvYHR","outputId":"0096f57d-2558-448f-d85b-0c43300cbcd1","execution":{"iopub.status.busy":"2022-01-11T12:08:46.845975Z","iopub.execute_input":"2022-01-11T12:08:46.847967Z","iopub.status.idle":"2022-01-11T12:09:09.718753Z","shell.execute_reply.started":"2022-01-11T12:08:46.847929Z","shell.execute_reply":"2022-01-11T12:09:09.709494Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#transfer model to cuda for acceleration\nmodel.to(device)","metadata":{"id":"DgJLqEK6vgfI","outputId":"6bf4255e-9a4e-43b5-818a-b8fe0b1056d8","execution":{"iopub.status.busy":"2022-01-11T12:09:09.720245Z","iopub.execute_input":"2022-01-11T12:09:09.720762Z","iopub.status.idle":"2022-01-11T12:09:09.884423Z","shell.execute_reply.started":"2022-01-11T12:09:09.720722Z","shell.execute_reply":"2022-01-11T12:09:09.883745Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#intialise optimiser for GD\noptimizer = torch.optim.Adam(model.parameters(), lr = 2e-5, eps = 1e-8)\n#initialise scheduler to reduce LR on val loss plateau\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)","metadata":{"id":"f1bUnByywAVh","execution":{"iopub.status.busy":"2022-01-11T12:09:09.887149Z","iopub.execute_input":"2022-01-11T12:09:09.889866Z","iopub.status.idle":"2022-01-11T12:09:09.898938Z","shell.execute_reply.started":"2022-01-11T12:09:09.889827Z","shell.execute_reply":"2022-01-11T12:09:09.898113Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#code to move data to GPU from: https://www.kaggle.com/mihirpaghdal/intel-image-classification\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"id":"8adgi80P3zR4","execution":{"iopub.status.busy":"2022-01-11T12:09:09.904277Z","iopub.execute_input":"2022-01-11T12:09:09.910568Z","iopub.status.idle":"2022-01-11T12:09:09.922402Z","shell.execute_reply.started":"2022-01-11T12:09:09.910526Z","shell.execute_reply":"2022-01-11T12:09:09.921463Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#load data onto GPU if available\ntrainloader = DeviceDataLoader(trainloader, device)\nvalloader = DeviceDataLoader(valloader, device)\ntestloader = DeviceDataLoader(testloader, device)","metadata":{"id":"N0SMbEvt3q7R","execution":{"iopub.status.busy":"2022-01-11T12:09:09.927632Z","iopub.execute_input":"2022-01-11T12:09:09.930344Z","iopub.status.idle":"2022-01-11T12:09:09.937263Z","shell.execute_reply.started":"2022-01-11T12:09:09.930277Z","shell.execute_reply":"2022-01-11T12:09:09.936272Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"def run_training(num_epochs):\n    #record losses to plot later\n    train_loss_list = []\n    val_loss_list = []\n    #initialise early stopping object\n    early_stopping = EarlyStopping(patience=3, verbose=True)\n\n    for k in range(num_epochs):\n        #training mode\n        model.train()\n        total_training_loss = 0\n        i=0\n        for label, token, attention in trainloader:\n            optimizer.zero_grad()\n            #use BERT to get loss\n            output = model(input_ids=token, \n                              attention_mask=attention, \n                              labels=label)\n            loss = output['loss']\n            #get only the loss value using loss.item instead of storing entire graph\n            total_training_loss+=loss.item()\n            #calculate gradients\n            loss.backward()\n            #clip gradients to 1 prevent exploding\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            #take one step in GD\n            optimizer.step()\n            i+=1\n        #calculate average training loss for the number of batches\n        avg_train_loss = total_training_loss/i\n        train_loss_list.append(avg_train_loss)\n\n        #eval mode\n        model.eval()\n        total_validation_loss = 0\n        i = 0\n        for label, token, attention in valloader:\n            #dont need to calculate gradients to reduce memory\n            with torch.no_grad():\n                output = model(input_ids=token, \n                                attention_mask=attention, \n                                labels=label)\n                loss = output['loss']\n                total_validation_loss+=loss.item()\n                i+=1\n        #calculate average val loss for the number of batches\n        avg_val_loss = total_validation_loss/i\n        val_loss_list.append(avg_val_loss)\n        \n        #check if early stopping is required\n        early_stopping(avg_val_loss, model)\n        \n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n\n        #see if need to reduce learning rate\n        scheduler.step(avg_val_loss)\n\n        print(f'epoch: {k+1}, train loss: {avg_train_loss}, val loss: {avg_val_loss}')\n\n    #load the best model so far to return\n    model.load_state_dict(torch.load('checkpoint.pt'))\n    \n    return model, train_loss_list, val_loss_list","metadata":{"id":"C2zSJOxlwiZD","execution":{"iopub.status.busy":"2022-01-11T12:09:09.942726Z","iopub.execute_input":"2022-01-11T12:09:09.945587Z","iopub.status.idle":"2022-01-11T12:09:09.965291Z","shell.execute_reply.started":"2022-01-11T12:09:09.945549Z","shell.execute_reply":"2022-01-11T12:09:09.964555Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#maximum epochs set to 15\nmodel, train_loss_list, val_loss_list = run_training(15)","metadata":{"id":"qJTSKyrAyH_K","outputId":"2717ab97-c9e9-4e18-f45f-a4f95e60fabf","execution":{"iopub.status.busy":"2022-01-11T12:09:09.971089Z","iopub.execute_input":"2022-01-11T12:09:09.974074Z","iopub.status.idle":"2022-01-11T12:13:26.580963Z","shell.execute_reply.started":"2022-01-11T12:09:09.974030Z","shell.execute_reply":"2022-01-11T12:13:26.580255Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Test Results","metadata":{}},{"cell_type":"code","source":"#create confusion matrix dataframe to plot later\ncf_matrix = pd.DataFrame(list(itertools.product(classes, classes)))\ncf_matrix.rename(columns = {0:'Actual', 1:'Predicted'}, inplace=True)\ncf_matrix['Num_Obs']=0\nclasses = classes.to_list()","metadata":{"id":"zPWnuHyOg7MU","execution":{"iopub.status.busy":"2022-01-11T12:13:26.582479Z","iopub.execute_input":"2022-01-11T12:13:26.582815Z","iopub.status.idle":"2022-01-11T12:13:26.590119Z","shell.execute_reply.started":"2022-01-11T12:13:26.582775Z","shell.execute_reply":"2022-01-11T12:13:26.589149Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#testing accuracy\nmodel.eval()\nnum_correct = 0\ntotal = 0\n#turn logits into probability\nsoftmax = torch.nn.Softmax(dim=1)\n\nwith torch.no_grad():\n    for i, batch in enumerate(testloader):\n        label, token, attention = batch\n        output = model(input_ids=token, \n                      attention_mask=attention, \n                      labels=label)\n        logits = output['logits']\n        probability = softmax(logits)\n        predictions = torch.max(probability, dim=1).indices\n        num_correct+=(predictions == label).sum().item()\n        total+= label.size(0)\n        #adding predictions to confusion matrix df\n        for actual, predicted in zip(label, predictions):\n            actual = classes[actual.item()]\n            predicted = classes[predicted.item()]\n            cf_matrix.loc[((cf_matrix['Actual']==actual) & (cf_matrix['Predicted']==predicted)), 'Num_Obs']+=1\n    \nprint(f'Accuracy is {(num_correct/total)*100}%')","metadata":{"id":"Tpa8ZQmLLWD5","outputId":"fab924ee-d33c-40b5-d746-bff2faf7e1b1","execution":{"iopub.status.busy":"2022-01-11T12:13:26.591365Z","iopub.execute_input":"2022-01-11T12:13:26.592169Z","iopub.status.idle":"2022-01-11T12:13:28.528799Z","shell.execute_reply.started":"2022-01-11T12:13:26.592131Z","shell.execute_reply":"2022-01-11T12:13:28.527352Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Accuracy is around 87-88%.","metadata":{}},{"cell_type":"code","source":"#plot confusion matrix in heatmap\ncf_matrix = cf_matrix.pivot(\"Actual\", \"Predicted\", \"Num_Obs\")\n\nsns.heatmap(data=cf_matrix, annot=True)","metadata":{"id":"XhWOv40-VECE","outputId":"d3bf266f-657a-4674-a816-ccc94a495322","execution":{"iopub.status.busy":"2022-01-11T12:13:28.529903Z","iopub.execute_input":"2022-01-11T12:13:28.530139Z","iopub.status.idle":"2022-01-11T12:13:29.201471Z","shell.execute_reply.started":"2022-01-11T12:13:28.530105Z","shell.execute_reply":"2022-01-11T12:13:29.200766Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"The model can differentiate between the classes well for most of the classes. However it has more difficulty differentiating between anxiety and depression.","metadata":{}},{"cell_type":"code","source":"#obtain training and validation loss curve\n#create dataframes for seaborn visualisation\ntrainloss_df = pd.DataFrame(train_loss_list, columns=['value'])\ntrainloss_df['type']='training_loss'\ntrainloss_df['epoch_num']=range(len(train_loss_list))\ntrainloss_df['epoch_num']=trainloss_df['epoch_num']+1\nvalloss_df = pd.DataFrame(val_loss_list, columns=['value'])\nvalloss_df['type']='valid_loss'\nvalloss_df['epoch_num']=range(len(val_loss_list))\nvalloss_df['epoch_num']=valloss_df['epoch_num']+1\ncombined_df = pd.concat([trainloss_df, valloss_df])\ncombined_df.reset_index(drop=True, inplace=True)\n#plot train and val loss over epochs\nsns.lineplot(data=combined_df,x='epoch_num', y='value', hue='type')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:13:29.202578Z","iopub.execute_input":"2022-01-11T12:13:29.203624Z","iopub.status.idle":"2022-01-11T12:13:29.449380Z","shell.execute_reply.started":"2022-01-11T12:13:29.203581Z","shell.execute_reply":"2022-01-11T12:13:29.448729Z"},"trusted":true},"execution_count":38,"outputs":[]}]}